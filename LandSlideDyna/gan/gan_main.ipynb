{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# append the path of the parent directory\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gan_dataset import LandslideDataset, RandomRotationFlipTransform\n",
    "from gan_generator import GeneratorUNet\n",
    "from gan_discriminator import Discriminator\n",
    "from gan_pix2pix import Pix2PixGAN, Pix2PixGenerator  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the main directory where subfolders with model IDs are present\n",
    "main_directory = r'C:\\Users\\thomas.bush\\repos\\dyna-landslide-surrogate\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of subfolder names, which are your model IDs\n",
    "model_ids = [subfolder for subfolder in os.listdir(main_directory) \n",
    "             if os.path.isdir(os.path.join(main_directory, subfolder))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train/validation/test\n",
    "train_val_ids, test_ids = train_test_split(model_ids, test_size=0.2, random_state=42)\n",
    "train_ids, val_ids = train_test_split(train_val_ids, test_size=0.05, random_state=42)\n",
    "\n",
    "# Create dataset objects for each set\n",
    "train_dataset = LandslideDataset(base_dir=main_directory, model_ids=train_ids)\n",
    "val_dataset = LandslideDataset(base_dir=main_directory, model_ids=val_ids)\n",
    "test_dataset = LandslideDataset(base_dir=main_directory, model_ids=test_ids)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scalers for each feature\n",
    "elevation_scaler = MinMaxScaler()\n",
    "thickness_0_scaler = MinMaxScaler()\n",
    "thickness_max_scaler = MinMaxScaler()\n",
    "velocity_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scalers on the training data\n",
    "for sample in train_dataset:\n",
    "    elevation_scaler.partial_fit(sample['input'][0].reshape(-1, 1))\n",
    "    thickness_0_scaler.partial_fit(sample['input'][1].reshape(-1, 1))\n",
    "    thickness_max_scaler.partial_fit(sample['target'][1].reshape(-1, 1))\n",
    "    velocity_max_scaler.partial_fit(sample['target'][0].reshape(-1, 1))\n",
    "\n",
    "# Create a dictionary of scalers\n",
    "scaler = {\n",
    "    'elevation': elevation_scaler,\n",
    "    'thickness_0': thickness_0_scaler,\n",
    "    'thickness_max': thickness_max_scaler,\n",
    "    'velocity_max': velocity_max_scaler\n",
    "}\n",
    "\n",
    "# Pass the scaler dictionary to the dataset\n",
    "train_dataset.scaler = scaler\n",
    "val_dataset.scaler = scaler\n",
    "test_dataset.scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the scaler on the training data\n",
    "# scaler = StandardScaler()\n",
    "# for sample in train_dataset:\n",
    "#     input_data = sample['input'].numpy()\n",
    "#     # Reshape the input_data from (channels, height, width) to (height * width, channels)\n",
    "#     reshaped_input_data = input_data.reshape(-1, input_data.shape[0])\n",
    "#     scaler.partial_fit(reshaped_input_data)\n",
    "\n",
    "# # Apply the scaler to all datasets\n",
    "# train_dataset.scaler = scaler\n",
    "# val_dataset.scaler = scaler\n",
    "# test_dataset.scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomRotationFlipTransform()\n",
    "train_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize transformed samples from the training dataset\n",
    "# num_samples_to_visualize = 20\n",
    "# for i in range(num_samples_to_visualize):\n",
    "#     sample = train_dataset[i]\n",
    "#     input_data = sample['input']\n",
    "#     target_data = sample['target']\n",
    "\n",
    "#     plt.figure(figsize=(12, 4))\n",
    "\n",
    "#     plt.subplot(1, 4, 1)\n",
    "#     plt.imshow(input_data[0], cmap='gray')\n",
    "#     plt.title(\"Input Topography\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 4, 2)\n",
    "#     plt.imshow(input_data[1], cmap='jet')\n",
    "#     plt.title(\"Input Initial Thickness\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 4, 3)\n",
    "#     plt.imshow(target_data[1], cmap='jet')\n",
    "#     plt.title(\"Expected Max Thickness\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(1, 4, 4)\n",
    "#     plt.imshow(target_data[0], cmap='jet')\n",
    "#     plt.title(\"Expected Max Velocity\")\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for DataLoader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "num_workers = 4  # Adjust based on your system\n",
    "\n",
    "# Create DataLoader for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "generator = GeneratorUNet(input_channels=2, output_channels=2, apply_mask=True)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the Pix2Pix GAN model\n",
    "# pix2pix_gan = Pix2PixGAN(generator.to(device), discriminator.to(device), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Pix2Pix GENERATOR ONLY model\n",
    "pix2pix_gan = Pix2PixGenerator(generator.to(device), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpix2pix_gan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\repos\\dyna-landslide-surrogate\\LandSlideDyna\\gan\\gan_pix2pix.py:152\u001b[0m, in \u001b[0;36mPix2PixGenerator.train\u001b[1;34m(self, train_loader, val_loader, epochs, val_interval)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Generate fake target image from the source image\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m fake_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Calculate the generator loss\u001b[39;00m\n\u001b[0;32m    155\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_loss(fake_image, target_image)\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\AppData\\Local\\miniforge3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\AppData\\Local\\miniforge3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\repos\\dyna-landslide-surrogate\\LandSlideDyna\\gan\\gan_generator.py:253\u001b[0m, in \u001b[0;36mGeneratorUNet.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m    251\u001b[0m u1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(middle, d7)\n\u001b[0;32m    252\u001b[0m u2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup2(u1, d6)\n\u001b[1;32m--> 253\u001b[0m u3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m u4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup4(u3, d4)\n\u001b[0;32m    255\u001b[0m u5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup5(u4, d3)\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\AppData\\Local\\miniforge3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\AppData\\Local\\miniforge3\\envs\\cuda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\thomas.bush\\repos\\dyna-landslide-surrogate\\LandSlideDyna\\gan\\gan_generator.py:202\u001b[0m, in \u001b[0;36mUNetUp.forward\u001b[1;34m(self, x, skip_input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout:\n\u001b[0;32m    201\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m--> 202\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 2 but got size 3 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "pix2pix_gan.train(train_loader=train_loader, val_loader=val_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pix2pix_gan.predict(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(real_image, real_initial_thickness, real_thickness, real_velocity, fake_thickness, fake_velocity, dataloader):\n",
    "    # Inverse scaling for real images\n",
    "    elevation_scaler = dataloader.dataset.scaler['elevation']\n",
    "    thickness_0_scaler = dataloader.dataset.scaler['thickness_0']\n",
    "    thickness_max_scaler = dataloader.dataset.scaler['thickness_max']\n",
    "    velocity_max_scaler = dataloader.dataset.scaler['velocity_max']\n",
    "\n",
    "    real_image = elevation_scaler.inverse_transform(real_image.cpu().numpy().reshape(-1, 1)).reshape(real_image.shape)\n",
    "    real_initial_thickness = thickness_0_scaler.inverse_transform(real_initial_thickness.cpu().numpy().reshape(-1, 1)).reshape(real_initial_thickness.shape)\n",
    "    real_thickness = thickness_max_scaler.inverse_transform(real_thickness.cpu().numpy().reshape(-1, 1)).reshape(real_thickness.shape)\n",
    "    real_velocity = velocity_max_scaler.inverse_transform(real_velocity.cpu().numpy().reshape(-1, 1)).reshape(real_velocity.shape)\n",
    "\n",
    "    # Calculate differences\n",
    "    thickness_diff = real_thickness - fake_thickness.squeeze().cpu().numpy()\n",
    "    velocity_diff = real_velocity - fake_velocity.squeeze().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(20, 12))  # Adjusted for additional space for colorbars and rows\n",
    "\n",
    "    # Input Topography with Colorbar\n",
    "    ax1 = plt.subplot(3, 4, 1)\n",
    "    im1 = ax1.imshow(real_image, cmap='gray')\n",
    "    plt.title(\"Input Topography\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im1, ax=ax1, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Input Initial Thickness with Colorbar\n",
    "    ax2 = plt.subplot(3, 4, 2)\n",
    "    vmin_thickness = min(real_initial_thickness.min(), real_thickness.min(), fake_thickness.min(), thickness_diff.min())\n",
    "    vmax_thickness = max(real_initial_thickness.max(), real_thickness.max(), fake_thickness.max(), thickness_diff.max())\n",
    "    im2 = ax2.imshow(real_initial_thickness, cmap='jet', vmin=vmin_thickness, vmax=vmax_thickness)\n",
    "    plt.title(\"Input Initial Thickness\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im2, ax=ax2, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Expected Max Thickness with Colorbar\n",
    "    ax3 = plt.subplot(3, 4, 5)\n",
    "    im3 = ax3.imshow(real_thickness, cmap='jet', vmin=vmin_thickness, vmax=vmax_thickness)\n",
    "    plt.title(\"Expected Max Thickness\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im3, ax=ax3, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Predicted Max Thickness with Colorbar\n",
    "    ax4 = plt.subplot(3, 4, 6)\n",
    "    im4 = ax4.imshow(fake_thickness.squeeze().cpu().numpy(), cmap='jet', vmin=vmin_thickness, vmax=vmax_thickness)\n",
    "    plt.title(\"Predicted Max Thickness\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im4, ax=ax4, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Max Thickness Difference with Colorbar\n",
    "    ax5 = plt.subplot(3, 4, 7)\n",
    "    im5 = ax5.imshow(thickness_diff, cmap='jet', vmin=vmin_thickness, vmax=vmax_thickness)\n",
    "    plt.title(\"Max Thickness Difference\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im5, ax=ax5, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Expected Max Velocity with Colorbar\n",
    "    ax6 = plt.subplot(3, 4, 9)\n",
    "    vmin_velocity = min(real_velocity.min(), fake_velocity.min(), velocity_diff.min())\n",
    "    vmax_velocity = max(real_velocity.max(), fake_velocity.max(), velocity_diff.max())\n",
    "    im6 = ax6.imshow(real_velocity, cmap='jet', vmin=vmin_velocity, vmax=vmax_velocity)\n",
    "    plt.title(\"Expected Max Velocity\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im6, ax=ax6, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Predicted Max Velocity with Colorbar\n",
    "    ax7 = plt.subplot(3, 4, 10)\n",
    "    im7 = ax7.imshow(fake_velocity.squeeze().cpu().numpy(), cmap='jet', vmin=vmin_velocity, vmax=vmax_velocity)\n",
    "    plt.title(\"Predicted Max Velocity\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im7, ax=ax7, fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Max Velocity Difference with Colorbar\n",
    "    ax8 = plt.subplot(3, 4, 11)\n",
    "    im8 = ax8.imshow(velocity_diff, cmap='jet', vmin=vmin_velocity, vmax=vmax_velocity)\n",
    "    plt.title(\"Max Velocity Difference\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(im8, ax=ax8, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set the number of predictions to show\n",
    "num_predictions_to_show = 10\n",
    "\n",
    "# Randomly select indices from the test dataset\n",
    "selected_indices = random.sample(range(len(test_dataset)), num_predictions_to_show)\n",
    "\n",
    "# Iterate over the selected indices\n",
    "for index in selected_indices:\n",
    "    # Get the corresponding source image, fake thickness, and fake velocity\n",
    "    source_image, fake_thickness, fake_velocity = predictions[index // batch_size]\n",
    "    batch_index = index % batch_size\n",
    "\n",
    "    real_image = source_image[batch_index, 0]  # Take the corresponding batch item and the first channel (topography)\n",
    "    real_initial_thickness = source_image[batch_index, 1]  # Take the corresponding batch item and the second channel (initial thickness)\n",
    "    real_target = test_dataset[index]['target']  # Take the corresponding item from the test dataset\n",
    "    real_thickness, real_velocity = real_target[1], real_target[0]  # Split the real target into thickness and velocity\n",
    "    show_images(real_image, real_initial_thickness, real_thickness, real_velocity, fake_thickness[batch_index], fake_velocity[batch_index], test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyna-landslide-surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
