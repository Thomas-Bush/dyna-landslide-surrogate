{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# append the path of the parent directory\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# External library imports\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# internal library imports\n",
    "from dataset import DebrisStatePairsDataset\n",
    "from model import CNN, UNet\n",
    "from train import TrainerPairs, CustomDebrisLoss\n",
    "from util.setting_utils import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for multiple libraries to ensure repeatability\n",
    "\n",
    "# set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_losses(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    # Extract the subfolder name as the series name\n",
    "    series_name = os.path.basename(os.path.dirname(file_path))\n",
    "    return series_name, data['training_losses'], data['validation_losses']\n",
    "\n",
    "def plot_multiple_losses(files, log_y=False):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for file_path in files:\n",
    "        series_name, training_losses, validation_losses = read_losses(file_path)\n",
    "        epochs = range(1, len(training_losses) + 1)\n",
    "        \n",
    "\n",
    "        # plt.plot(epochs, training_losses, 'o-', label=f'{series_name} Training', linewidth=2)\n",
    "        \n",
    "        plt.plot(epochs, validation_losses, 'o--', label=f'{series_name} Validation', linewidth=2)\n",
    "\n",
    "    plt.title('Training and Validation Losses for Multiple Models')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if log_y:\n",
    "        plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-26_09-10_FIN_base_model_compar_smoothl1Loss_batch32_timestep1_lr1e-4_l2reg_drop0-2_expdata_prune_CNN/losses_epoch_50.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-26_09-10_FIN_base_model_compar_smoothl1Loss_batch32_timestep1_lr1e-4_l2reg_drop0-2_expdata_prune_SmallUNet/losses_epoch_50.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-26_09-10_FIN_base_model_compar_smoothl1Loss_batch32_timestep1_lr1e-4_l2reg_drop0-2_expdata_prune_MedUNet/losses_epoch_50.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-26_09-10_FIN_base_model_compar_smoothl1Loss_batch32_timestep1_lr1e-4_l2reg_drop0-2_expdata_prune_LargeUNet/losses_epoch_50.json'\n",
    "]\n",
    "\n",
    "plot_multiple_losses(files, log_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-21_base_model_comparison_l1Loss_batch32_lr1e-4_CNN/losses_epoch_30.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-21_base_model_comparison_l1Loss_batch32_lr1e-4_SmallUNet/losses_epoch_30.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-21_base_model_comparison_l1Loss_batch32_lr1e-4_MedUNet/losses_epoch_30.json',\n",
    "    '/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-21_base_model_comparison_l1Loss_batch32_lr1e-4_LargeUNet/losses_epoch_30.json'\n",
    "]\n",
    "\n",
    "plot_multiple_losses(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "root_dir = r'/home/tom/repos/dyna-landslide-surrogate/data_experiment_prune'\n",
    "checkpoint_dir = r'/home/tom/repos/dyna-landslide-surrogate/checkpoints'\n",
    "batch_size = 32\n",
    "split_proportions = (0.7, 0.15, 0.15)\n",
    "epochs = 30\n",
    "\n",
    "in_channels = 3  # Number of input channels (e.g., terrain, velocity, thickness)\n",
    "out_channels = 2  # Number of output channels (e.g., next velocity, next thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set up\n",
    "\n",
    "# Initialize dataset with scaling\n",
    "dataset = DebrisStatePairsDataset(root_dir, array_size=256, apply_scaling=True, timestep_interval=1)\n",
    "\n",
    "# Split dataset into train, validation, and test sets and create dataloaders\n",
    "train_loader, val_loader, test_loader = dataset.create_dataloaders(split_proportions, batch_size, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset stats\n",
    "print(f\"Total dataset size: {len(dataset)}\")\n",
    "print(f\"Train size: {len(train_loader.dataset)}, Validation size: {len(val_loader.dataset)}, Test size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "med_unet = UNet(in_channels=3, out_channels=2, features=[64, 128, 256, 512]).to(device)\n",
    "\n",
    "# Check if multiple GPUs are available and wrap the model using nn.DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    # This will wrap the model for use with multiple GPUs\n",
    "    med_unet = nn.DataParallel(med_unet)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.L1Loss()\n",
    "# criterion = CustomDebrisLoss(loss_fn_zero=nn.SmoothL1Loss(), loss_fn_debris=nn.SmoothL1Loss(), debris_weight=0.66)\n",
    "optimizer = Adam(med_unet.parameters(), lr=1e-3)\n",
    "\n",
    "med_unet_trainer = TrainerPairs(med_unet, optimizer, criterion, device, model_name=\"med_unet\", checkpoint_dir=checkpoint_dir)\n",
    "\n",
    "med_unet_trainer.load_checkpoint(\"/home/tom/repos/dyna-landslide-surrogate/checkpoints/2024-04-26_09-10_FIN_base_model_compar_smoothl1Loss_batch32_timestep1_lr1e-4_l2reg_drop0-2_expdata_prune_MedUNet/model_epoch_50.pth\", train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_unet_trainer.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_unet_trainer.plot_predictions(test_loader, num_predictions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_unet_trainer.plot_predictions6(test_loader, num_predictions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_vs_inferred(real_states, inferred_states, base_folder, model_id, suffix='', n=5):\n",
    "    num_timesteps = len(real_states)\n",
    "    timesteps_to_plot = range(1, num_timesteps + 1, n)  # Start from 1 and go up to num_timesteps + 1\n",
    "\n",
    "    # Create the folder for the model_id with the suffix if provided\n",
    "    model_folder = os.path.join(base_folder, str(model_id) + suffix)\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "    for timestep in timesteps_to_plot:\n",
    "        real_state = real_states[timestep]\n",
    "        inferred_state = inferred_states[timestep]\n",
    "\n",
    "        # Extract velocity and thickness from real and inferred states\n",
    "        real_velocity = real_state[0]  # Real velocity is at index 0\n",
    "        real_thickness = real_state[1]  # Real thickness is at index 1\n",
    "        inferred_velocity = inferred_state[1]  # Inferred velocity is at index 1\n",
    "        inferred_thickness = inferred_state[0]  # Inferred thickness is at index 0\n",
    "\n",
    "        # Calculate differences\n",
    "        velocity_diff = np.abs(real_velocity - inferred_velocity)\n",
    "        thickness_diff = np.abs(real_thickness - inferred_thickness)\n",
    "\n",
    "        # Determine the common color scales for velocities and thicknesses\n",
    "        velocity_min = min(np.min(real_velocity), np.min(inferred_velocity), np.min(velocity_diff))\n",
    "        velocity_max = max(np.max(real_velocity), np.max(inferred_velocity), np.max(velocity_diff))\n",
    "        thickness_min = min(np.min(real_thickness), np.min(inferred_thickness), np.min(thickness_diff))\n",
    "        thickness_max = max(np.max(real_thickness), np.max(inferred_thickness), np.max(thickness_diff))\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 8))\n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "        # Row 1: Real Velocity, Inferred Velocity, Velocity Difference\n",
    "        axes[0, 0].imshow(real_velocity, cmap='jet', vmin=velocity_min, vmax=velocity_max)\n",
    "        axes[0, 0].set_title(f'Real Velocity (Timestep {timestep})')\n",
    "        axes[0, 0].axis('off')\n",
    "        fig.colorbar(axes[0, 0].imshow(real_velocity, cmap='jet', vmin=velocity_min, vmax=velocity_max), ax=axes[0, 0])\n",
    "\n",
    "        axes[0, 1].imshow(inferred_velocity, cmap='jet', vmin=velocity_min, vmax=velocity_max)\n",
    "        axes[0, 1].set_title(f'Inferred Velocity (Timestep {timestep})')\n",
    "        axes[0, 1].axis('off')\n",
    "        fig.colorbar(axes[0, 1].imshow(inferred_velocity, cmap='jet', vmin=velocity_min, vmax=velocity_max), ax=axes[0, 1])\n",
    "\n",
    "        axes[0, 2].imshow(velocity_diff, cmap='jet', vmin=velocity_min, vmax=velocity_max)\n",
    "        axes[0, 2].set_title(f'Velocity Difference (Timestep {timestep})')\n",
    "        axes[0, 2].axis('off')\n",
    "        fig.colorbar(axes[0, 2].imshow(velocity_diff, cmap='jet', vmin=velocity_min, vmax=velocity_max), ax=axes[0, 2])\n",
    "\n",
    "        # Row 2: Real Thickness, Inferred Thickness, Thickness Difference\n",
    "        axes[1, 0].imshow(real_thickness, cmap='jet', vmin=thickness_min, vmax=thickness_max)\n",
    "        axes[1, 0].set_title(f'Real Thickness (Timestep {timestep})')\n",
    "        axes[1, 0].axis('off')\n",
    "        fig.colorbar(axes[1, 0].imshow(real_thickness, cmap='jet', vmin=thickness_min, vmax=thickness_max), ax=axes[1, 0])\n",
    "\n",
    "        axes[1, 1].imshow(inferred_thickness, cmap='jet', vmin=thickness_min, vmax=thickness_max)\n",
    "        axes[1, 1].set_title(f'Inferred Thickness (Timestep {timestep})')\n",
    "        axes[1, 1].axis('off')\n",
    "        fig.colorbar(axes[1, 1].imshow(inferred_thickness, cmap='jet', vmin=thickness_min, vmax=thickness_max), ax=axes[1, 1])\n",
    "\n",
    "        axes[1, 2].imshow(thickness_diff, cmap='jet', vmin=thickness_min, vmax=thickness_max)\n",
    "        axes[1, 2].set_title(f'Thickness Difference (Timestep {timestep})')\n",
    "        axes[1, 2].axis('off')\n",
    "        fig.colorbar(axes[1, 2].imshow(thickness_diff, cmap='jet', vmin=thickness_min, vmax=thickness_max), ax=axes[1, 2])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()  # Display the plot in the notebook\n",
    "\n",
    "        # Save the figure as a 300 dpi PNG file\n",
    "        filename = f'state_{timestep}.png'\n",
    "        save_path = os.path.join(model_folder, filename)\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Stack all inferred arrays and all actual arrays\n",
    "    stacked_inferred_velocity = np.stack([state[1] for state in inferred_states.values()], axis=0)\n",
    "    stacked_inferred_thickness = np.stack([state[0] for state in inferred_states.values()], axis=0)\n",
    "    stacked_real_velocity = np.stack([state[0] for state in real_states.values()], axis=0)\n",
    "    stacked_real_thickness = np.stack([state[1] for state in real_states.values()], axis=0)\n",
    "\n",
    "    # Determine the common color scales for stacked velocities and thicknesses\n",
    "    stacked_velocity_min = min(np.min(stacked_real_velocity), np.min(stacked_inferred_velocity))\n",
    "    stacked_velocity_max = max(np.max(stacked_real_velocity), np.max(stacked_inferred_velocity))\n",
    "    stacked_thickness_min = min(np.min(stacked_real_thickness), np.min(stacked_inferred_thickness))\n",
    "    stacked_thickness_max = max(np.max(stacked_real_thickness), np.max(stacked_inferred_thickness))\n",
    "\n",
    "    # Plot stacked arrays side by side\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 8))\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    axes[0, 0].imshow(stacked_real_velocity.max(axis=0), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max)\n",
    "    axes[0, 0].set_title('Stacked Real Velocity')\n",
    "    axes[0, 0].axis('off')\n",
    "    fig.colorbar(axes[0, 0].imshow(stacked_real_velocity.max(axis=0), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max), ax=axes[0, 0])\n",
    "\n",
    "    axes[0, 1].imshow(stacked_inferred_velocity.max(axis=0), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max)\n",
    "    axes[0, 1].set_title('Stacked Inferred Velocity')\n",
    "    axes[0, 1].axis('off')\n",
    "    fig.colorbar(axes[0, 1].imshow(stacked_inferred_velocity.max(axis=0), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max), ax=axes[0, 1])\n",
    "\n",
    "    axes[0, 2].imshow(np.abs(stacked_real_velocity.max(axis=0) - stacked_inferred_velocity.max(axis=0)), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max)\n",
    "    axes[0, 2].set_title('Stacked Velocity Difference')\n",
    "    axes[0, 2].axis('off')\n",
    "    fig.colorbar(axes[0, 2].imshow(np.abs(stacked_real_velocity.max(axis=0) - stacked_inferred_velocity.max(axis=0)), cmap='jet', vmin=stacked_velocity_min, vmax=stacked_velocity_max), ax=axes[0, 2])\n",
    "\n",
    "    axes[1, 0].imshow(stacked_real_thickness.max(axis=0), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max)\n",
    "    axes[1, 0].set_title('Stacked Real Thickness')\n",
    "    axes[1, 0].axis('off')\n",
    "    fig.colorbar(axes[1, 0].imshow(stacked_real_thickness.max(axis=0), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max), ax=axes[1, 0])\n",
    "\n",
    "    axes[1, 1].imshow(stacked_inferred_thickness.max(axis=0), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max)\n",
    "    axes[1, 1].set_title('Stacked Inferred Thickness')\n",
    "    axes[1, 1].axis('off')\n",
    "    fig.colorbar(axes[1, 1].imshow(stacked_inferred_thickness.max(axis=0), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max), ax=axes[1, 1])\n",
    "\n",
    "    axes[1, 2].imshow(np.abs(stacked_real_thickness.max(axis=0) - stacked_inferred_thickness.max(axis=0)), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max)\n",
    "    axes[1, 2].set_title('Stacked Thickness Difference')\n",
    "    axes[1, 2].axis('off')\n",
    "    fig.colorbar(axes[1, 2].imshow(np.abs(stacked_real_thickness.max(axis=0) - stacked_inferred_thickness.max(axis=0)), cmap='jet', vmin=stacked_thickness_min, vmax=stacked_thickness_max), ax=axes[1, 2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Display the stacked plot in the notebook\n",
    "\n",
    "    # Save the stacked plot as a 300 dpi PNG file\n",
    "    filename = 'stacked_plots.png'\n",
    "    save_path = os.path.join(model_folder, filename)\n",
    "    fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "def create_real_states_dict(root_dir, model_number, start_state, num_timesteps, array_size):\n",
    "    real_states = {}\n",
    "    \n",
    "    model_dir = os.path.join(root_dir, str(model_number))\n",
    "    velocity_dir = os.path.join(model_dir, f'04_FinalProcessedData_{array_size}', 'velocity')\n",
    "    thickness_dir = os.path.join(model_dir, f'04_FinalProcessedData_{array_size}', 'thickness')\n",
    "    \n",
    "    for t in range(num_timesteps):\n",
    "        state_number = start_state + t\n",
    "        \n",
    "        velocity_file = os.path.join(velocity_dir, f'{model_number}_velocity_{state_number}.npy')\n",
    "        thickness_file = os.path.join(thickness_dir, f'{model_number}_thickness_{state_number}.npy')\n",
    "        \n",
    "        velocity = np.load(velocity_file)\n",
    "        thickness = np.load(thickness_file)\n",
    "        \n",
    "        real_states[t + 1] = np.stack((thickness, velocity), axis=0)  # Change the key to t + 1\n",
    "    \n",
    "    return real_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roughly how to use\n",
    "\n",
    "Does some weird stuff with the class though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/home/tom/repos/dyna-landslide-surrogate/plots\"\n",
    "\n",
    "n = 10\n",
    "num_timesteps = 50\n",
    "model = \"00076\"\n",
    "start = 2\n",
    "\n",
    "\n",
    "# Create the initial input\n",
    "initial_input = med_unet_trainer.create_inference_input(root_dir, model, start, 256)\n",
    "\n",
    "# Perform inference\n",
    "\n",
    "inferred_states = med_unet_trainer.infer(initial_input, num_timesteps)\n",
    "\n",
    "# Create the real states dictionary\n",
    "real_states = create_real_states_dict(root_dir, model, start + 1, num_timesteps, 256)\n",
    "\n",
    "# Plot real vs inferred states\n",
    "plot_real_vs_inferred(real_states, inferred_states, model_id=model, n=n, base_folder=base_folder, suffix=\"chain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_infer = med_unet_trainer.infer_from_real_states(real_states, num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_real_vs_inferred(real_states, state_infer, n=n, model_id=model, base_folder=base_folder, suffix='pairs')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyna-landslide-surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
