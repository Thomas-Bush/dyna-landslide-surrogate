{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Tuple, Union, List, Dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DebrisFlowDataset(Dataset):\n",
    "    \"\"\"A PyTorch Dataset for loading debris flow data, preparing it for CNN-LSTM models.\"\"\"\n",
    "\n",
    "    def __init__(self, main_dir: str, scaling_params: Dict[str, Dict[str, Union[None, float]]]):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with the main data directory and scaling parameters.\n",
    "\n",
    "        Args:\n",
    "            main_dir (str): The main directory where the data is stored.\n",
    "            scaling_params (dict): A dictionary containing scaling parameters for each channel.\n",
    "        \"\"\"\n",
    "        self.main_dir = main_dir\n",
    "        self.scaling_params = scaling_params\n",
    "        self.file_paths = self._gather_file_paths()\n",
    "\n",
    "    def _gather_file_paths(self) -> List[Tuple[str, str, str]]:\n",
    "        \"\"\"Gather and pair file paths for elevation, thickness, and velocity channels.\"\"\"\n",
    "        file_paths = []\n",
    "        for dirpath, _, filenames in os.walk(self.main_dir):\n",
    "            if 'elevation' in dirpath:\n",
    "                # Assume corresponding thickness and velocity files share the same prefix\n",
    "                for elevation_file in filenames:\n",
    "                    prefix = elevation_file.split('_elevation')[0]\n",
    "                    thickness_file = f\"{prefix}_thickness.npy\"\n",
    "                    velocity_file = f\"{prefix}_velocity.npy\"\n",
    "                    if os.path.exists(os.path.join(dirpath, thickness_file)) and \\\n",
    "                       os.path.exists(os.path.join(dirpath, velocity_file)):\n",
    "                        file_paths.append((\n",
    "                            os.path.join(dirpath, elevation_file),\n",
    "                            os.path.join(dirpath, thickness_file),\n",
    "                            os.path.join(dirpath, velocity_file)\n",
    "                        ))\n",
    "        return file_paths\n",
    "\n",
    "    def _scale_data(self, data: np.ndarray, channel_name: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Scale the data for a given channel using scaling parameters.\n",
    "\n",
    "        Args:\n",
    "            data (np.ndarray): The data to scale.\n",
    "            channel_name (str): The name of the channel to which the data belongs.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: Scaled data.\n",
    "        \"\"\"\n",
    "        median = self.scaling_params[channel_name]['median']\n",
    "        mad = self.scaling_params[channel_name]['mad']\n",
    "        return (data - median) / mad if median is not None and mad is not None else data\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Denotes the total number of samples.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get the item at the given index in the form of a multi-channel image.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the item.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing torch.Tensors for the elevation, thickness, and velocity channels.\n",
    "        \"\"\"\n",
    "        elevation_path, thickness_path, velocity_path = self.file_paths[idx]\n",
    "\n",
    "        # Load data\n",
    "        elevation = np.load(elevation_path)\n",
    "        thickness = np.load(thickness_path)\n",
    "        velocity = np.load(velocity_path)\n",
    "\n",
    "        # Scale data\n",
    "        elevation_scaled = self._scale_data(elevation, 'elevation')\n",
    "        thickness_scaled = self._scale_data(thickness, 'thickness')\n",
    "        velocity_scaled = self._scale_data(velocity, 'velocity')\n",
    "\n",
    "        # Convert to torch.Tensor and stack as channels\n",
    "        image = torch.tensor(np.stack((elevation_scaled, thickness_scaled, velocity_scaled), axis=0),\n",
    "                             dtype=torch.float32)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_channel_scaling_params(elevation_files, thickness_files, velocity_files):\n",
    "    \"\"\"Compute the non-zero median and MAD for each channel using unique filenames.\n",
    "\n",
    "    This function processes the given files for each channel to compute the \n",
    "    non-zero median and MAD, which are useful for data normalization.\n",
    "\n",
    "    Args:\n",
    "        elevation_files (set): A set of unique elevation filenames.\n",
    "        thickness_files (set): A set of unique thickness filenames.\n",
    "        velocity_files (set): A set of unique velocity filenames.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the dictionaries of median and MAD values for each channel.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(elevation_files)} elevation files, {len(thickness_files)} thickness files, and {len(velocity_files)} velocity files.\")\n",
    "    \n",
    "    def compute_median_and_mad(channel_data):\n",
    "        \"\"\"Compute the median and MAD of non-zero values in the data.\"\"\"\n",
    "        non_zero_data = channel_data[channel_data != 0].flatten()\n",
    "        median_val = np.median(non_zero_data)\n",
    "        mad_val = np.median(np.abs(non_zero_data - median_val))\n",
    "        return median_val, mad_val\n",
    "\n",
    "    median_vals = {}\n",
    "    mad_vals = {}\n",
    "\n",
    "    for channel_files, channel in zip([elevation_files, thickness_files, velocity_files], ['elevation', 'thickness', 'velocity']):\n",
    "        start_time = time.time()\n",
    "        channel_data = np.concatenate([np.load(file) for file in channel_files])\n",
    "        median_vals[channel], mad_vals[channel] = compute_median_and_mad(channel_data)\n",
    "        del channel_data  # Free up memory\n",
    "        print(f\"Processed {channel} files in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    return median_vals, mad_vals\n",
    "\n",
    "def set_channel_scaling_params_to_dataset(dataset, median_vals, mad_vals):\n",
    "    \"\"\"Apply the computed non-zero median and MAD values for each channel to the dataset.\n",
    "\n",
    "    This function updates the dataset with scaling parameters for each channel, which are used\n",
    "    for normalization during preprocessing.\n",
    "\n",
    "    Args:\n",
    "        dataset (DebrisFlowDataset): The dataset to apply the scaling parameters to.\n",
    "        median_vals (dict): A dictionary containing the non-zero median values for each channel.\n",
    "        mad_vals (dict): A dictionary containing the MAD values for each channel.\n",
    "    \"\"\"\n",
    "    scaling_params = {channel: {'median': median_vals[channel], 'mad': mad_vals[channel]}\n",
    "                      for channel in ['elevation', 'thickness', 'velocity']}\n",
    "    dataset.set_scaling_params(scaling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediumUNetPlus(nn.Module):\n",
    "    \"\"\"A basic U-Net architecture for semantic segmentation with dropout regularization.\n",
    "\n",
    "    Attributes:\n",
    "        enc1: First encoder block.\n",
    "        enc2: Second encoder block.\n",
    "        enc3: Third encoder block.\n",
    "        enc4: Fourth encoder block.\n",
    "        bottleneck: The bottleneck part of the network including dropout layers.\n",
    "        dec1: First decoder block.\n",
    "        dec2: Second decoder block.\n",
    "        dec3: Third decoder block.\n",
    "        dec4: Fourth decoder block.\n",
    "        out_conv: Final output convolutional layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.5):\n",
    "        \"\"\"Initializes the BasicUNet with the given number of input and output channels and dropout rate.\n",
    "\n",
    "        Args:\n",
    "            in_channels: The number of input channels.\n",
    "            out_channels: The number of output channels.\n",
    "            dropout_rate: The dropout rate to use in the bottleneck and decoder blocks.\n",
    "        \"\"\"\n",
    "        super(MediumUNetPlus, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.encoder_block(in_channels, 32)\n",
    "        self.enc2 = self.encoder_block(32, 64)\n",
    "        self.enc3 = self.encoder_block(64, 128)\n",
    "        self.enc4 = self.encoder_block(128, 256)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.dec1 = self.decoder_block(512 + 256, 256, dropout_rate)\n",
    "        self.dec2 = self.decoder_block(256 + 128, 128, dropout_rate)\n",
    "        self.dec3 = self.decoder_block(128 + 64, 64, dropout_rate)\n",
    "        self.dec4 = self.decoder_block(64 + 32, 32, dropout_rate)\n",
    "\n",
    "        # Final output\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def encoder_block(self, in_channels, out_channels):\n",
    "        \"\"\"Creates an encoder block with Convolution, Batch Normalization, ReLU activation, and MaxPooling.\n",
    "\n",
    "        Args:\n",
    "            in_channels: The number of input channels for the block.\n",
    "            out_channels: The number of output channels for the block.\n",
    "\n",
    "        Returns:\n",
    "            An nn.Sequential module comprising the encoder block layers.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def decoder_block(self, in_channels, out_channels, dropout_rate):\n",
    "        \"\"\"Creates a decoder block with Convolution, Batch Normalization, ReLU activation, Dropout, and Upsampling.\n",
    "\n",
    "        Args:\n",
    "            in_channels: The number of input channels for the block.\n",
    "            out_channels: The number of output channels for the block.\n",
    "            dropout_rate: The dropout rate to use after convolutional layers.\n",
    "\n",
    "        Returns:\n",
    "            An nn.Sequential module comprising the decoder block layers.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Defines the forward pass of the BasicUNet with skip connections.\n",
    "\n",
    "        Args:\n",
    "            x: The input tensor.\n",
    "\n",
    "        Returns:\n",
    "            The output tensor after passing through the U-Net.\n",
    "        \"\"\"\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(e4)\n",
    "\n",
    "        # Decoder with skip connections\n",
    "        d1 = self.dec1(torch.cat((e4, b), dim=1))\n",
    "        d2 = self.dec2(torch.cat((e3, d1), dim=1))\n",
    "        d3 = self.dec3(torch.cat((e2, d2), dim=1))\n",
    "        d4 = self.dec4(torch.cat((e1, d3), dim=1))\n",
    "\n",
    "        # Final output\n",
    "        out = self.out_conv(d4)\n",
    "\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
