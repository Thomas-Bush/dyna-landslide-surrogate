{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "  \n",
    "# append the path of the parent directory\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import FileUtils\n",
    "from visualisation import ArrayVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata_to_dataframe(base_dir, folder_names):\n",
    "        \"\"\"Read JSON files from specified folders into a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "            base_dir (str): The base directory containing the folders.\n",
    "            folder_names (list): List of folder names containing the JSON files.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A Pandas DataFrame containing the data from the JSON files.\n",
    "        \"\"\"\n",
    "        data_list = []\n",
    "\n",
    "        # Iterate over the folder names\n",
    "        for folder_name in folder_names:\n",
    "            file_path = os.path.join(base_dir, folder_name, f\"{folder_name}_metadata.json\")\n",
    "\n",
    "            # Read the JSON file, ensuring it exists\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "                    # Remove the 'timesteps' key from the data\n",
    "                    data.pop('timesteps', None)\n",
    "                    data_list.append(data)\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "\n",
    "        # Convert the list of dictionaries to a DataFrame\n",
    "        return pd.DataFrame(data_list)\n",
    "\n",
    "def enhance_metadata(df):\n",
    "    \"\"\"Enhance the DataFrame by adding x_dimension, y_dimension, and z_dimension columns.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the metadata.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The enhanced DataFrame with new dimension columns.\n",
    "    \"\"\"\n",
    "    # Calculate dimensions based on the min and max values\n",
    "    df['x_dimension'] = df['max_x_value'] - df['min_x_value']\n",
    "    df['y_dimension'] = df['max_y_value'] - df['min_y_value']\n",
    "    df['z_dimension'] = df['max_z_value'] - df['min_z_value']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# def load_and_analyze_states(base_dir, model_ids):\n",
    "#     \"\"\"Load arrays for each state and perform checks on them.\n",
    "\n",
    "#     Args:\n",
    "#         base_dir (str): The base directory containing the model folders.\n",
    "#         model_ids (list): List of model IDs corresponding to subfolders.\n",
    "\n",
    "#     Returns:\n",
    "#         pandas.DataFrame: DataFrame with bounding box details for all states and the largest bounding box.\n",
    "#     \"\"\"\n",
    "#     results_data = []\n",
    "\n",
    "#     for model_id in model_ids:\n",
    "#         overall_min_x = overall_max_x = None\n",
    "#         overall_min_y = overall_max_y = None\n",
    "#         largest_bounding_box_dimensions = (0, 0)\n",
    "#         largest_bounding_box_state = None\n",
    "#         largest_bounding_box_coords = None\n",
    "\n",
    "#         thickness_dir = os.path.join(base_dir, model_id, 'thickness')\n",
    "#         velocity_dir = os.path.join(base_dir, model_id, 'velocity')\n",
    "\n",
    "#         # Load real-world x and y coordinates\n",
    "#         x_values = np.load(os.path.join(thickness_dir, f\"{model_id}_thickness_x_values.npy\"))\n",
    "#         y_values = np.load(os.path.join(thickness_dir, f\"{model_id}_thickness_y_values.npy\"))\n",
    "\n",
    "#         state_no = 1\n",
    "#         while True:\n",
    "#             thickness_file = os.path.join(thickness_dir, f\"{model_id}_thickness_{state_no}.npy\")\n",
    "#             velocity_file = os.path.join(velocity_dir, f\"{model_id}_velocity_{state_no}.npy\")\n",
    "\n",
    "#             # Check if both thickness and velocity files exist\n",
    "#             if not os.path.exists(thickness_file) or not os.path.exists(velocity_file):\n",
    "#                 break  # No more states to process\n",
    "\n",
    "#             thickness_array = np.load(thickness_file)\n",
    "#             velocity_array = np.load(velocity_file)\n",
    "\n",
    "#             # Determine the min and max xy coordinates of the debris\n",
    "#             non_zero_indices = np.where((thickness_array > 0) & (velocity_array > 0))\n",
    "#             if non_zero_indices[0].size > 0:\n",
    "#                 min_x, max_x = x_values[non_zero_indices[1].min()], x_values[non_zero_indices[1].max()]\n",
    "#                 min_y, max_y = y_values[non_zero_indices[0].min()], y_values[non_zero_indices[0].max()]\n",
    "\n",
    "#                 # Update overall bounding box\n",
    "#                 overall_min_x = min(overall_min_x, min_x) if overall_min_x is not None else min_x\n",
    "#                 overall_max_x = max(overall_max_x, max_x) if overall_max_x is not None else max_x\n",
    "#                 overall_min_y = min(overall_min_y, min_y) if overall_min_y is not None else min_y\n",
    "#                 overall_max_y = max(overall_max_y, max_y) if overall_max_y is not None else max_y\n",
    "\n",
    "#                 # Update largest bounding box state\n",
    "#                 bounding_box_dimensions = (max_x - min_x, max_y - min_y)\n",
    "#                 if np.prod(bounding_box_dimensions) > np.prod(largest_bounding_box_dimensions):\n",
    "#                     largest_bounding_box_dimensions = bounding_box_dimensions\n",
    "#                     largest_bounding_box_state = state_no\n",
    "#                     largest_bounding_box_coords = (min_x, max_x, min_y, max_y)\n",
    "\n",
    "#             state_no += 1\n",
    "\n",
    "#         # Log the results for the current model\n",
    "#         if overall_min_x is not None and overall_min_y is not None:\n",
    "#             results_data.append({\n",
    "#                 'model_id': model_id,\n",
    "#                 'overall_min_x': overall_min_x,\n",
    "#                 'overall_max_x': overall_max_x,\n",
    "#                 'overall_dim_x': overall_max_x - overall_min_x,\n",
    "#                 'overall_min_y': overall_min_y,\n",
    "#                 'overall_max_y': overall_max_y,\n",
    "#                 'overall_dim_y': overall_max_y - overall_min_y,\n",
    "#                 'largest_bounding_box_state': largest_bounding_box_state,\n",
    "#                 'largest_bounding_box_min_x': largest_bounding_box_coords[0],\n",
    "#                 'largest_bounding_box_max_x': largest_bounding_box_coords[1],\n",
    "#                 'largest_bounding_box_dim_x': largest_bounding_box_dimensions[0],\n",
    "#                 'largest_bounding_box_min_y': largest_bounding_box_coords[2],\n",
    "#                 'largest_bounding_box_max_y': largest_bounding_box_coords[3],\n",
    "#                 'largest_bounding_box_dim_y': largest_bounding_box_dimensions[1]\n",
    "#             })\n",
    "\n",
    "#     # Convert results to a DataFrame\n",
    "#     results_df = pd.DataFrame(results_data)\n",
    "#     return results_df\n",
    "\n",
    "\n",
    "def find_largest_bounding_box(base_dir, model_ids):\n",
    "    \"\"\"Find the largest bounding box dimensions and state with the largest bounding box.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory where model data is stored.\n",
    "        model_ids (list): A list of model IDs to process.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the overall bounding box dimensions and the details of the state with the largest bounding box.\n",
    "    \"\"\"\n",
    "    largest_bbox = {\n",
    "        'min_x': float('inf'),\n",
    "        'min_y': float('inf'),\n",
    "        'max_x': -float('inf'),\n",
    "        'max_y': -float('inf'),\n",
    "    }\n",
    "    largest_state_bbox = {\n",
    "        'state_id': None,\n",
    "        'min_x': float('inf'),\n",
    "        'min_y': float('inf'),\n",
    "        'max_x': -float('inf'),\n",
    "        'max_y': -float('inf'),\n",
    "        'dim_x': 0,\n",
    "        'dim_y': 0\n",
    "    }\n",
    "\n",
    "    for model_id in model_ids:\n",
    "        states_dir = os.path.join(base_dir, model_id, 'states')\n",
    "\n",
    "        for state_file in os.listdir(states_dir):\n",
    "            state_path = os.path.join(states_dir, state_file)\n",
    "            state_data = np.load(state_path)\n",
    "\n",
    "            # Assuming the state data is a structured array with 'x', 'y', 'thickness', 'velocity' fields\n",
    "            active_indices = np.nonzero(state_data['thickness'] * state_data['velocity'])\n",
    "            if active_indices[0].size == 0:  # Skip if there's no active debris\n",
    "                continue\n",
    "\n",
    "            min_x, max_x = state_data['x'][active_indices].min(), state_data['x'][active_indices].max()\n",
    "            min_y, max_y = state_data['y'][active_indices].min(), state_data['y'][active_indices].max()\n",
    "\n",
    "            # Update overall bounding box\n",
    "            largest_bbox['min_x'] = min(largest_bbox['min_x'], min_x)\n",
    "            largest_bbox['min_y'] = min(largest_bbox['min_y'], min_y)\n",
    "            largest_bbox['max_x'] = max(largest_bbox['max_x'], max_x)\n",
    "            largest_bbox['max_y'] = max(largest_bbox['max_y'], max_y)\n",
    "\n",
    "            # Check if this state has the largest bounding box\n",
    "            state_dim_x = max_x - min_x\n",
    "            state_dim_y = max_y - min_y\n",
    "            if state_dim_x * state_dim_y > largest_state_bbox['dim_x'] * largest_state_bbox['dim_y']:\n",
    "                largest_state_bbox.update({\n",
    "                    'state_id': state_file,\n",
    "                    'min_x': min_x,\n",
    "                    'min_y': min_y,\n",
    "                    'max_x': max_x,\n",
    "                    'max_y': max_y,\n",
    "                    'dim_x': state_dim_x,\n",
    "                    'dim_y': state_dim_y\n",
    "                })\n",
    "\n",
    "    overall_dim_x = largest_bbox['max_x'] - largest_bbox['min_x']\n",
    "    overall_dim_y = largest_bbox['max_y'] - largest_bbox['min_y']\n",
    "\n",
    "    return (\n",
    "        (largest_bbox['min_x'], largest_bbox['max_x'], largest_bbox['min_y'], largest_bbox['max_y'], overall_dim_x, overall_dim_y),\n",
    "        largest_state_bbox\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_analyze_states(base_dir, model_ids):\n",
    "    \"\"\"Load arrays for each state and perform checks on them, including max velocity and thickness.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): The base directory containing the model folders.\n",
    "        model_ids (list): List of model IDs corresponding to subfolders.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with bounding box details and max velocity and thickness for all states.\n",
    "    \"\"\"\n",
    "    results_data = []\n",
    "\n",
    "    for model_id in model_ids:\n",
    "        overall_min_x = overall_max_x = None\n",
    "        overall_min_y = overall_max_y = None\n",
    "        largest_bounding_box_dimensions = (0, 0)\n",
    "        largest_bounding_box_state = None\n",
    "        largest_bounding_box_coords = None\n",
    "        max_velocity = 0\n",
    "        max_thickness = 0\n",
    "\n",
    "        thickness_dir = os.path.join(base_dir, model_id, 'thickness')\n",
    "        velocity_dir = os.path.join(base_dir, model_id, 'velocity')\n",
    "\n",
    "        # Load real-world x and y coordinates\n",
    "        x_values = np.load(os.path.join(thickness_dir, f\"{model_id}_thickness_x_values.npy\"))\n",
    "        y_values = np.load(os.path.join(thickness_dir, f\"{model_id}_thickness_y_values.npy\"))\n",
    "\n",
    "        state_no = 1\n",
    "        while True:\n",
    "            thickness_file = os.path.join(thickness_dir, f\"{model_id}_thickness_{state_no}.npy\")\n",
    "            velocity_file = os.path.join(velocity_dir, f\"{model_id}_velocity_{state_no}.npy\")\n",
    "\n",
    "            # Check if both thickness and velocity files exist\n",
    "            if not os.path.exists(thickness_file) or not os.path.exists(velocity_file):\n",
    "                break  # No more states to process\n",
    "\n",
    "            thickness_array = np.load(thickness_file)\n",
    "            velocity_array = np.load(velocity_file)\n",
    "\n",
    "            # Update max velocity and thickness\n",
    "            max_velocity = max(max_velocity, np.max(velocity_array))\n",
    "            max_thickness = max(max_thickness, np.max(thickness_array))\n",
    "\n",
    "            # Determine the min and max xy coordinates of the debris\n",
    "            non_zero_indices = np.where((thickness_array > 0) & (velocity_array > 0))\n",
    "            if non_zero_indices[0].size > 0:\n",
    "                min_x, max_x = x_values[non_zero_indices[1].min()], x_values[non_zero_indices[1].max()]\n",
    "                min_y, max_y = y_values[non_zero_indices[0].min()], y_values[non_zero_indices[0].max()]\n",
    "\n",
    "                # Update overall bounding box\n",
    "                overall_min_x = min(overall_min_x, min_x) if overall_min_x is not None else min_x\n",
    "                overall_max_x = max(overall_max_x, max_x) if overall_max_x is not None else max_x\n",
    "                overall_min_y = min(overall_min_y, min_y) if overall_min_y is not None else min_y\n",
    "                overall_max_y = max(overall_max_y, max_y) if overall_max_y is not None else max_y\n",
    "\n",
    "                # Update largest bounding box state\n",
    "                bounding_box_dimensions = (max_x - min_x, max_y - min_y)\n",
    "                if np.prod(bounding_box_dimensions) > np.prod(largest_bounding_box_dimensions):\n",
    "                    largest_bounding_box_dimensions = bounding_box_dimensions\n",
    "                    largest_bounding_box_state = state_no\n",
    "                    largest_bounding_box_coords = (min_x, max_x, min_y, max_y)\n",
    "\n",
    "            state_no += 1\n",
    "\n",
    "        # Log the results for the current model\n",
    "        if overall_min_x is not None and overall_min_y is not None:\n",
    "            results_data.append({\n",
    "                'model_id': model_id,\n",
    "                'overall_min_x': overall_min_x,\n",
    "                'overall_max_x': overall_max_x,\n",
    "                'overall_dim_x': overall_max_x - overall_min_x,\n",
    "                'overall_min_y': overall_min_y,\n",
    "                'overall_max_y': overall_max_y,\n",
    "                'overall_dim_y': overall_max_y - overall_min_y,\n",
    "                'largest_bounding_box_state': largest_bounding_box_state,\n",
    "                'largest_bounding_box_min_x': largest_bounding_box_coords[0],\n",
    "                'largest_bounding_box_max_x': largest_bounding_box_coords[1],\n",
    "                'largest_bounding_box_dim_x': largest_bounding_box_dimensions[0],\n",
    "                'largest_bounding_box_min_y': largest_bounding_box_coords[2],\n",
    "                'largest_bounding_box_max_y': largest_bounding_box_coords[3],\n",
    "                'largest_bounding_box_dim_y': largest_bounding_box_dimensions[1],\n",
    "                'max_velocity': max_velocity,\n",
    "                'max_thickness': max_thickness\n",
    "            })\n",
    "\n",
    "                # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'../data/processed'\n",
    "\n",
    "model_ids = FileUtils.get_subfolder_names(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = read_metadata_to_dataframe(data_dir, model_ids)\n",
    "\n",
    "metadata_df = enhance_metadata(metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>total_number_of_states</th>\n",
       "      <th>min_x_value</th>\n",
       "      <th>max_x_value</th>\n",
       "      <th>min_y_value</th>\n",
       "      <th>max_y_value</th>\n",
       "      <th>min_z_value</th>\n",
       "      <th>max_z_value</th>\n",
       "      <th>grid_resolution_x</th>\n",
       "      <th>grid_resolution_y</th>\n",
       "      <th>average_timestep</th>\n",
       "      <th>x_dimension</th>\n",
       "      <th>y_dimension</th>\n",
       "      <th>z_dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005</td>\n",
       "      <td>242</td>\n",
       "      <td>815893.0</td>\n",
       "      <td>816305.0</td>\n",
       "      <td>832859.0</td>\n",
       "      <td>833143.0</td>\n",
       "      <td>24.010</td>\n",
       "      <td>168.9250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.497922</td>\n",
       "      <td>412.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>144.9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004</td>\n",
       "      <td>122</td>\n",
       "      <td>816083.0</td>\n",
       "      <td>816295.0</td>\n",
       "      <td>832881.0</td>\n",
       "      <td>833097.0</td>\n",
       "      <td>24.765</td>\n",
       "      <td>125.5725</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.495858</td>\n",
       "      <td>212.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>100.8075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007</td>\n",
       "      <td>122</td>\n",
       "      <td>815939.0</td>\n",
       "      <td>816331.0</td>\n",
       "      <td>832754.0</td>\n",
       "      <td>833062.0</td>\n",
       "      <td>23.050</td>\n",
       "      <td>158.5975</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>392.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>135.5475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006</td>\n",
       "      <td>242</td>\n",
       "      <td>815950.0</td>\n",
       "      <td>816304.0</td>\n",
       "      <td>832833.0</td>\n",
       "      <td>833171.0</td>\n",
       "      <td>23.905</td>\n",
       "      <td>164.1925</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.497921</td>\n",
       "      <td>354.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>140.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>122</td>\n",
       "      <td>822649.0</td>\n",
       "      <td>822811.0</td>\n",
       "      <td>822644.0</td>\n",
       "      <td>822728.0</td>\n",
       "      <td>0.840</td>\n",
       "      <td>83.2100</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.495861</td>\n",
       "      <td>162.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.3700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id  total_number_of_states  min_x_value  max_x_value  min_y_value  \\\n",
       "0     0005                     242     815893.0     816305.0     832859.0   \n",
       "1     0004                     122     816083.0     816295.0     832881.0   \n",
       "2     0007                     122     815939.0     816331.0     832754.0   \n",
       "3     0006                     242     815950.0     816304.0     832833.0   \n",
       "4     0001                     122     822649.0     822811.0     822644.0   \n",
       "\n",
       "   max_y_value  min_z_value  max_z_value  grid_resolution_x  \\\n",
       "0     833143.0       24.010     168.9250                2.0   \n",
       "1     833097.0       24.765     125.5725                2.0   \n",
       "2     833062.0       23.050     158.5975                2.0   \n",
       "3     833171.0       23.905     164.1925                2.0   \n",
       "4     822728.0        0.840      83.2100                3.0   \n",
       "\n",
       "   grid_resolution_y  average_timestep  x_dimension  y_dimension  z_dimension  \n",
       "0                2.0          0.497922        412.0        284.0     144.9150  \n",
       "1                2.0          0.495858        212.0        216.0     100.8075  \n",
       "2                2.0          0.495868        392.0        308.0     135.5475  \n",
       "3                2.0          0.497921        354.0        338.0     140.2875  \n",
       "4                3.0          0.495861        162.0         84.0      82.3700  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = load_and_analyze_states(data_dir, model_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>overall_min_x</th>\n",
       "      <th>overall_max_x</th>\n",
       "      <th>overall_dim_x</th>\n",
       "      <th>overall_min_y</th>\n",
       "      <th>overall_max_y</th>\n",
       "      <th>overall_dim_y</th>\n",
       "      <th>largest_bounding_box_state</th>\n",
       "      <th>largest_bounding_box_min_x</th>\n",
       "      <th>largest_bounding_box_max_x</th>\n",
       "      <th>largest_bounding_box_dim_x</th>\n",
       "      <th>largest_bounding_box_min_y</th>\n",
       "      <th>largest_bounding_box_max_y</th>\n",
       "      <th>largest_bounding_box_dim_y</th>\n",
       "      <th>max_velocity</th>\n",
       "      <th>max_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0005</td>\n",
       "      <td>815945.0</td>\n",
       "      <td>816121.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>832945.0</td>\n",
       "      <td>833093.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>234</td>\n",
       "      <td>816033.0</td>\n",
       "      <td>816121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>832945.0</td>\n",
       "      <td>832963.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>283.24</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0004</td>\n",
       "      <td>816135.0</td>\n",
       "      <td>816203.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>832949.0</td>\n",
       "      <td>833043.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>27</td>\n",
       "      <td>816151.0</td>\n",
       "      <td>816195.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>832959.0</td>\n",
       "      <td>833019.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>99.00</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0007</td>\n",
       "      <td>816009.0</td>\n",
       "      <td>816199.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>832824.0</td>\n",
       "      <td>832956.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>76</td>\n",
       "      <td>816143.0</td>\n",
       "      <td>816197.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>832920.0</td>\n",
       "      <td>832956.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>321.13</td>\n",
       "      <td>5.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006</td>\n",
       "      <td>816000.0</td>\n",
       "      <td>816180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>832937.0</td>\n",
       "      <td>833089.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>216</td>\n",
       "      <td>816080.0</td>\n",
       "      <td>816178.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>832937.0</td>\n",
       "      <td>832961.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>327.83</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001</td>\n",
       "      <td>822667.0</td>\n",
       "      <td>822784.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>822656.0</td>\n",
       "      <td>822707.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>30</td>\n",
       "      <td>822703.0</td>\n",
       "      <td>822745.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>822665.0</td>\n",
       "      <td>822689.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>320.32</td>\n",
       "      <td>13.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id  overall_min_x  overall_max_x  overall_dim_x  overall_min_y  \\\n",
       "0     0005       815945.0       816121.0          176.0       832945.0   \n",
       "1     0004       816135.0       816203.0           68.0       832949.0   \n",
       "2     0007       816009.0       816199.0          190.0       832824.0   \n",
       "3     0006       816000.0       816180.0          180.0       832937.0   \n",
       "4     0001       822667.0       822784.0          117.0       822656.0   \n",
       "\n",
       "   overall_max_y  overall_dim_y  largest_bounding_box_state  \\\n",
       "0       833093.0          148.0                         234   \n",
       "1       833043.0           94.0                          27   \n",
       "2       832956.0          132.0                          76   \n",
       "3       833089.0          152.0                         216   \n",
       "4       822707.0           51.0                          30   \n",
       "\n",
       "   largest_bounding_box_min_x  largest_bounding_box_max_x  \\\n",
       "0                    816033.0                    816121.0   \n",
       "1                    816151.0                    816195.0   \n",
       "2                    816143.0                    816197.0   \n",
       "3                    816080.0                    816178.0   \n",
       "4                    822703.0                    822745.0   \n",
       "\n",
       "   largest_bounding_box_dim_x  largest_bounding_box_min_y  \\\n",
       "0                        88.0                    832945.0   \n",
       "1                        44.0                    832959.0   \n",
       "2                        54.0                    832920.0   \n",
       "3                        98.0                    832937.0   \n",
       "4                        42.0                    822665.0   \n",
       "\n",
       "   largest_bounding_box_max_y  largest_bounding_box_dim_y  max_velocity  \\\n",
       "0                    832963.0                        18.0        283.24   \n",
       "1                    833019.0                        60.0         99.00   \n",
       "2                    832956.0                        36.0        321.13   \n",
       "3                    832961.0                        24.0        327.83   \n",
       "4                    822689.0                        24.0        320.32   \n",
       "\n",
       "   max_thickness  \n",
       "0           6.05  \n",
       "1           5.88  \n",
       "2           5.95  \n",
       "3           7.30  \n",
       "4          13.43  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '0001'\n",
    "\n",
    "model_dir = r'/home/tom/repos/dyna-landslide-surrogate/data/processed'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_states_and_assess_outliers(model_dir, model_id):\n",
    "    \"\"\"Load thickness and velocity states for a model and conduct an outlier assessment, ignoring specific files.\n",
    "\n",
    "    Outliers are defined as values that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR for thickness and velocity.\n",
    "\n",
    "    Args:\n",
    "        model_dir (str): The directory containing the states for a specific model.\n",
    "        model_id (str): The ID of the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the outlier indices for thickness and velocity.\n",
    "    \"\"\"\n",
    "    thickness_data = []\n",
    "    velocity_data = []\n",
    "\n",
    "    # Define file patterns to ignore\n",
    "    ignore_files = {\n",
    "        f\"{model_id}_thickness_max_value.npy\",\n",
    "        f\"{model_id}_thickness_x_values.npy\",\n",
    "        f\"{model_id}_thickness_y_values.npy\",\n",
    "        f\"{model_id}_velocity_max_value.npy\",\n",
    "        f\"{model_id}_velocity_x_values.npy\",\n",
    "        f\"{model_id}_velocity_y_values.npy\"\n",
    "    }\n",
    "\n",
    "    # Load all states for thickness\n",
    "    thickness_dir = os.path.join(model_dir, model_id, 'thickness')\n",
    "    for thickness_file in sorted(os.listdir(thickness_dir)):\n",
    "        if thickness_file not in ignore_files and thickness_file.endswith('.npy'):\n",
    "            thickness_data.append(np.load(os.path.join(thickness_dir, thickness_file)))\n",
    "\n",
    "    # Load all states for velocity\n",
    "    velocity_dir = os.path.join(model_dir, model_id, 'velocity')\n",
    "    for velocity_file in sorted(os.listdir(velocity_dir)):\n",
    "        if velocity_file not in ignore_files and velocity_file.endswith('.npy'):\n",
    "            velocity_data.append(np.load(os.path.join(velocity_dir, velocity_file)))\n",
    "\n",
    "    # Convert to single arrays\n",
    "    thickness_data = np.concatenate(thickness_data)\n",
    "    velocity_data = np.concatenate(velocity_data)\n",
    "\n",
    "    # Outlier assessment based on IQR\n",
    "    def assess_outliers(data):\n",
    "        q1 = np.percentile(data, 25)\n",
    "        q3 = np.percentile(data, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        outliers = np.where((data < lower_bound) | (data > upper_bound))\n",
    "        return outliers\n",
    "\n",
    "    thickness_outliers = assess_outliers(thickness_data)\n",
    "    velocity_outliers = assess_outliers(velocity_data)\n",
    "\n",
    "    return {\n",
    "        'thickness_outliers': thickness_outliers,\n",
    "        'velocity_outliers': velocity_outliers\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thickness directory found: /home/tom/repos/dyna-landslide-surrogate/data/processed/0001/thickness\n",
      "Velocity directory found: /home/tom/repos/dyna-landslide-surrogate/data/processed/0001/velocity\n",
      "{'thickness_outliers': (array([  46,   46,   47, ..., 3520, 3520, 3520]), array([42, 43, 41, ..., 12, 13, 14])), 'velocity_outliers': (array([  45,   45,   45, ..., 3521, 3521, 3521]), array([40, 41, 42, ..., 14, 15, 16]))}\n"
     ]
    }
   ],
   "source": [
    "# Correct the model directory path\n",
    "\n",
    "\n",
    "# Check if the directories exist\n",
    "thickness_dir = os.path.join(model_dir, model_id, 'thickness')\n",
    "velocity_dir = os.path.join(model_dir, model_id, 'velocity')\n",
    "\n",
    "# Verify the thickness directory\n",
    "if not os.path.exists(thickness_dir):\n",
    "    print(f\"Thickness directory does not exist: {thickness_dir}\")\n",
    "else:\n",
    "    print(f\"Thickness directory found: {thickness_dir}\")\n",
    "\n",
    "# Verify the velocity directory\n",
    "if not os.path.exists(velocity_dir):\n",
    "    print(f\"Velocity directory does not exist: {velocity_dir}\")\n",
    "else:\n",
    "    print(f\"Velocity directory found: {velocity_dir}\")\n",
    "\n",
    "# If both directories exist, you can proceed to call the function\n",
    "if os.path.exists(thickness_dir) and os.path.exists(velocity_dir):\n",
    "    outliers = load_states_and_assess_outliers(model_dir, model_id)\n",
    "    print(outliers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
