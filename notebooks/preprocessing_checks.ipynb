{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_utils import add_parent_dir_to_path\n",
    "\n",
    "add_parent_dir_to_path()\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def check_and_update_status(model_dir):\n",
    "    \"\"\"Check the preprocessing status of each model in the data directory.\n",
    "\n",
    "    Args:\n",
    "        model_dir (str): The path to the data directory containing model subdirectories.\n",
    "\n",
    "    Returns:\n",
    "        None: It writes the status to `preprocess_status.json` at the top level of the data directory.\n",
    "    \"\"\"\n",
    "    status = {}\n",
    "    for model in os.listdir(model_dir):\n",
    "        model_path = os.path.join(model_dir, model)\n",
    "        if os.path.isdir(model_path):\n",
    "            d3plot_ptf_path = os.path.join(model_path, '01_d3plot/ptf/')\n",
    "            d3plot_image_path = os.path.join(model_path, '01_d3plot/image/')\n",
    "            extract_path = os.path.join(model_path, '02_extract/')\n",
    "            initial_process_path = os.path.join(model_path, '03_initial_process/')\n",
    "            final_process_path = os.path.join(model_path, '04_final_process/')\n",
    "\n",
    "            status[model] = {\n",
    "                \"ignore\": os.path.exists(os.path.join(model_path, 'ignore.txt')),\n",
    "                \"metadata\": os.path.exists(os.path.join(model_path, f\"{model}_metadata.json\")),\n",
    "                \"d3plot_ptf\": os.path.exists(d3plot_ptf_path) and any(file.endswith('.ptf') for file in os.listdir(d3plot_ptf_path)),\n",
    "                \"d3plot_image\": os.path.exists(d3plot_image_path) and bool(os.listdir(d3plot_image_path)),\n",
    "                \"extract\": os.path.exists(extract_path) and all(os.path.exists(os.path.join(extract_path, filename)) for filename in [\n",
    "                    f\"{model}_nodal_velocities.csv\",\n",
    "                    f\"{model}_nodes.csv\",\n",
    "                    f\"{model}_shells.csv\",\n",
    "                    f\"{model}_solid_thicknesses.csv\",\n",
    "                    f\"{model}_solids.csv\",\n",
    "                    f\"{model}_states.csv\"\n",
    "                ]),\n",
    "                \"initial_process\": os.path.exists(initial_process_path) and all(os.path.exists(os.path.join(initial_process_path, dirname)) and bool(os.listdir(os.path.join(initial_process_path, dirname))) for dirname in ['elevation', 'thickness', 'velocity']),\n",
    "                \"final_process\": os.path.exists(final_process_path) and all(os.path.exists(os.path.join(final_process_path, dirname)) and bool(os.listdir(os.path.join(final_process_path, dirname))) for dirname in ['elevation', 'thickness', 'velocity'])\n",
    "            }\n",
    "    \n",
    "    # Write the status to a JSON file at the top level of the data directory\n",
    "    with open(os.path.join(model_dir, 'preprocess_status.json'), 'w') as outfile:\n",
    "        json.dump(status, outfile, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"\\\\global\\EastAsia\\HKG\\Group\\GEO\\Specialism\\Engineering Geology\\AI\\01 LSDyna Surrogate\\Data\\data\"\n",
    "\n",
    "\n",
    "check_and_update_status(DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dyna-landslide-surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
